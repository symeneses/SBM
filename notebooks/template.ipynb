{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalable Bayesian Modeling\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/symeneses/SBM/blob/main/notebooks/template.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute only if executing in Google Colab\n",
    "# !rm -r ./src\n",
    "# !rm -r ./data\n",
    "# !git clone https://github.com/symeneses/SBM\n",
    "# !mv ./SBM/src ./src\n",
    "# !mv ./SBM/data ./data\n",
    "# !rm -r ./SBM\n",
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade numpyro==0.11.0 pymc==5.0.2 blackjax==0.9.6 seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "cores = os.cpu_count()\n",
    "os.environ[\"XLA_FLAGS\"] = f'--xla_force_host_platform_device_count={cores}'\n",
    "root_path = os.path.abspath(os.pardir)\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import pymc as pm\n",
    "\n",
    "from src.data import data_generator\n",
    "from src.handler import Handler\n",
    "from src.diagnostics import convergency_validator, dist_validator\n",
    "from src.plots import plot_ess_ps, plot_monitor\n",
    "\n",
    "pd.set_option('display.precision', 2)\n",
    "RANDOM_SEED = 8957\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Create a Pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) with the variables to be used to define the model.\n",
    "\n",
    "âœðŸ½ User input required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate the data, name the final results as data\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "In the following cells, write the code for the models you want to compare. To make comparing the models and results easier, use the same name of variables in each version of the model.\n",
    "\n",
    "**For models in PyMC:** Create an annotated function, as in the example, that returns a `pm.model.Model`.\n",
    "\n",
    "**For models in Numpyro:** Use the same variable names of the `DataFrame` `data` for the arguments of the function model. These arguments should contain only columns present in `data`.\n",
    "\n",
    "âœðŸ½ User input required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pymc_model_gen(data: pd.DataFrame) -> pm.model.Model:\n",
    "\n",
    "    with pm.Model() as pymc_model:\n",
    "        # Your model here\n",
    "        mu_alpha = pm.Normal(\"Î¼_Î±\", mu=0.0, sigma=1.0)\n",
    "    return pymc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS\n",
    "\n",
    "\n",
    "def model():\n",
    "    # Your model here\n",
    "    return\n",
    "\n",
    "numpyro_kernel = NUTS(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Here, we will create create valid [InferenceData](https://python.arviz.org/en/latest/api/generated/arviz.InferenceData.html) objects and a set of metrics to measure performance for the selected models, data sizes and samplers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multiple data sizes\n",
    "\n",
    "To have a benchmark using different data sizes, we will use the function `data_generator` which will use the original dataset to generate datasets with the given `sizes` or filtering the original data in the parameter `filters`. You can also add Gaussian noise to selected variables using the parameter `include_noise`.\n",
    "\n",
    "âœðŸ½ User input required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = []\n",
    "include_noise = []\n",
    "datasets = data_generator(data, include_noise=include_noise, sizes=data_sizes)\n",
    "# If you want to work only with the original data, use this instead\n",
    "# datasets = {\"original_size\": data}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "âš ï¸ You should at least use 2 chains to be able to calculate correctly the diagnostics.\n",
    "\n",
    "âœðŸ½ User input required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following path if working in Google Colab\n",
    "# output_path = \"data/results\"\n",
    "output_path = \"../data/results\"\n",
    "models = {\"pymc\": pymc_model_gen, \"numpyro\": numpyro_kernel}\n",
    "pymc_samplers = [\"default\", \"numpyro\", \"blackjax\"]\n",
    "draws = 2000\n",
    "tune = 2000\n",
    "# It's recommended to use between 2 and 4 chains\n",
    "chains = 2\n",
    "\n",
    "# sampling all models\n",
    "handler = Handler(models, datasets, pymc_samplers, output_path)\n",
    "infer_data, results = handler.execute(draws, tune, chains, RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Convergency\n",
    "\n",
    "After sampling, the function `convergency_validator` will help you know if the models have converged. This function use the [rank normalized splitR-hat](https://python.arviz.org/en/latest/api/generated/arviz.rhat.html).\n",
    "\n",
    "An $\\hat R$ > 1.05 indicates convergence failures. In this case, the results of the next step `Validate Results` **can't be considered** as they assumed the MCMC has converged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergency_validator(infer_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results \n",
    "\n",
    "To check that the models are sampling from the same distributions. The function `dist_validator` will estimate the ranges of the mean for each variable using the [MCSE](https://python.arviz.org/en/latest/api/generated/arviz.mcse.html) of one of the models as reference. You can either give a `seed` to choose a model randomly or give the key `ref_key` of a selected model. The reference model will be compared only with others using the same sample size.\n",
    "\n",
    "The percentages displayed indicate how many variables are within the calculated range using Â±3 sigma. The values should be in theory greater or equal to `95%` following a weaker [three-sigma rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val, summaries = dist_validator(infer_data, ref_key=\"pymc_default_1549\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monitor(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESS\n",
    "\n",
    "To determine the sampler performance, we use the **Effective Sample Size** ([ESS](https://python.arviz.org/en/latest/api/generated/arviz.ess.html])) calculated per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ess_ps(results, summaries, data_sizes=data_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ess_ps(results, summaries, data_sizes=[max(data_sizes)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rank the best across all data sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = results.drop(columns=[\"current_memory\", \"peak_memory\"])\n",
    "summary[\"rank\"] = summary.sort_values([\"size\", \"ess_mean/s\"], ascending=[True, False]) \\\n",
    "            .groupby(['size']) \\\n",
    "            .cumcount() + 1\n",
    "summary.sort_values([\"size\", \"rank\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best options in each data size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.query(\"rank == 1\").sort_values(\"size\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616692cf73cdbe2b85117ee01c3e807250ddb7cb8b880d6f64d7932c9d34e3f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
